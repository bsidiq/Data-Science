{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"proj1b.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e0f9b2de18190d9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Project 1B: Predicting Housing Prices in Cook County\n",
    "\n",
    "## Due Date: Thursday, October 27th, 11:59 PM\n",
    "\n",
    "### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the project, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the collaborators cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In part A of this project, you performed some basic exploratory data analysis (EDA), laying out the thought process that leads to certain modeling decisions. Then, you added a few new features to the dataset, cleaning the data as well in the process.\n",
    "\n",
    "In this project, you will specify and fit a linear model to a few features of the housing data to predict housing prices. Next, we will analyze the error of the model and brainstorm ways to improve the model's performance. Finally, we'll delve deeper into the implications of predictive modeling within the Cook County Assessor's Office (CCAO) case study, especially because statistical modeling is how the CCAO valuates properties. Given the history of racial discrimination in housing policy and property taxation in Cook County, consider the impacts of your modeling results as you work through this assignment - and think about what fairness might mean to property owners in Cook County.\n",
    "\n",
    "After this part of the project, you should be comfortable with:\n",
    "- Implementing a data processing pipeline using `pandas`\n",
    "- Using `scikit-learn` to build and fit linear models\n",
    "\n",
    "## Score Breakdown\n",
    "\n",
    "Question | Points\n",
    "----|----\n",
    "0 | 5\n",
    "1 | 2\n",
    "2 | 2\n",
    "3 | 3\n",
    "4 | 2\n",
    "5 | 2\n",
    "6 | 1\n",
    "7 | 4\n",
    "8 | 6\n",
    "9 | 1\n",
    "10 | 2\n",
    "11 | 1\n",
    "12 | 2\n",
    "Total | 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62cfd21463535cac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from ds100_utils import run_linear_regression_test\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('cook_county_data.zip') as item:\n",
    "    item.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e8fea30adc9d489b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"cook_county_train.csv\", index_col='Unnamed: 0')\n",
    "test_data = pd.read_csv(\"cook_county_test.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c841a2de55691502",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 204792 observations and 62 features in training data\n",
    "assert training_data.shape == (204792, 62)\n",
    "# 68264 observations and 61 features in test data\n",
    "assert test_data.shape == (68264, 61)\n",
    "# Sale Price is provided in the training data\n",
    "assert 'Sale Price' in training_data.columns.values\n",
    "# Sale Price is hidden in the test data\n",
    "assert 'Sale Price' not in test_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's remind ourselves of the data available to us in the Cook County dataset. Remember, a more detailed description of each variable is included in `codebook.txt`, which is in the same directory as this notebook). **If you did not attempt Project 1A,** you should take some time to familiarize yourself with the codebook before moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 0\n",
    "### Question 0a\n",
    "\"How much is a house worth?\" Who might be interested in an answer to this question? Please list at least three different parties (people or organizations) and state whether each one has an interest in seeing the value be high or low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary people, county, real estate agencies. \n",
    "I believe ordinary people either buyer or seller are intrested to see the value of a house. \n",
    "Counties are also interested in looking at house prices in order to predict property taxes and usually they don't care if the price is high or low.\n",
    "Real estate agencies are also the one interested in seeing the value of a house and predict new values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 0b\n",
    "\n",
    "Which of the following scenarios strike you as unfair and why? You can choose more than one. There is no single right answer but you must explain your reasoning.\n",
    "\n",
    "A. A homeowner whose home is assessed at a higher price than it would sell for.  \n",
    "B. A homeowner whose home is assessed at a lower price than it would sell for.  \n",
    "C. An assessment process that systematically overvalues inexpensive properties and undervalues expensive properties.  \n",
    "D. An assessment process that systematically undervalues inexpensive properties and overvalues expensive properties.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Because it will affect low income families and minorities as they would have to pay more property taxes compared to the majority. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 0c\n",
    "\n",
    "Consider a model that is fit to $n = 30$ training observations. Call the response $y$ (Log Sale Price), the predictions $\\hat{y}$, and the residuals $y - \\hat{y}$. Which of the following residual plots of $y$ versus $y - \\hat{y}$ correspond to a model that might make property assessments that result in to regressive taxation?\n",
    "\n",
    "![](res-plots.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q0c = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q0c</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q0c results: All test cases passed!"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q0c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CCAO Dataset\n",
    "\n",
    "The dataset you’ll be working with comes from the Cook County Assessor’s Office (CCAO) in Illinois, a government institution that determines property taxes across most of Chicago’s metropolitan area and its nearby suburbs. In the United States, all property owners are required to pay property taxes, which are then used to fund public services including education, road maintenance, and sanitation. These property tax assessments are based on property values estimated using statistical models that consider multiple factors, such as real estate value and construction cost.\n",
    "\n",
    "This system, however, is not without flaws. In late 2017, a lawsuit was filed against the office of Cook County Assessor Joseph Berrios for producing “[racially discriminatory assessments and taxes](https://www.chicagotribune.com/politics/ct-cook-county-board-assessor-berrios-met-20170718-story.html).\" The lawsuit included claims that the assessor’s office undervalued high-priced homes and overvalued low-priced homes, creating a visible divide along racial lines: Wealthy homeowners, who were typically white, [paid less in property taxes](https://www.clccrul.org/bpnc-v-berrios-facts?rq=berrios), whereas [working-class, non-white homeowners paid more](https://www.chicagotribune.com/news/breaking/ct-cook-county-assessor-berrios-sued-met-20171214-story.html).\n",
    "\n",
    "The Chicago Tribune's four-part series, \"[The Tax Divide](https://www.chicagotribune.com/investigations/ct-tax-divide-investigation-20180425-storygallery.html)\", delves into how this was uncovered: After \"compiling and analyzing more than 100 million property tax records from the years 2003 through 2015, along with thousands of pages of documents, then vetting the findings with top experts in the field,\" they discovered that \"residential assessments had been so far off the mark for so many years.\" You can read more about their investigation [here](https://apps.chicagotribune.com/news/watchdog/cook-county-property-tax-divide/assessments.html).\n",
    "\n",
    "And make sure to watch [Lecture 14](https://ds100.org/fa22/lecture/lec14/) before answering the following questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 0d\n",
    "\n",
    "What were the central problems with the earlier property tax system in Cook County as reported by the Chicago Tribune ? And what were the primary causes of these problems? (Note: in addition to reading the paragraph above you will need to watch the lecture to answer this question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central problems with the earlier property tax system in Cook County as reported by the Chicago Tribune was that for years the county's property tax system created an unequal burden on residents to homeowners who are well-off while punishing those living in minorities. The primary cuases were producing discrimination against the people of color and working class, specifically, the minorities. For instance, in the lecture we learned that several property owners were affected through this unfair tax burden like Braxton-Williams whose property valued $147550, which she believes at that time his/her property over-valued. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 0e\n",
    "\n",
    "In addition to being regressive, why did the property tax system in Cook County place a disproportionate tax burden on non-white property owners?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To impose racial inequality as real estate is one of the modern key motor of racial inequality in the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 1\n",
    "\n",
    "Now, let's split the data set into a training set and test set. We will use the training set to fit our model's parameters, and we will use the test set to estimate how well our model will perform on unseen data drawn from the same distribution. If we used all the data to fit our model, we would not have a way to estimate model performance on **unseen data**.\n",
    "\n",
    "\"Don't we already have a test set in `cook_county_test.csv`?\" you might wonder. The sale prices for `cook_county_test.csv` aren't provided, so we're constructing our own test set for which we know the outputs.\n",
    "\n",
    "In the cell below, complete the function `train_test_split` that splits `data` into two smaller DataFrames named `train` and `test`. Let `train` contain 80% of the data, and let `test` contain the remaining 20% of the data. \n",
    "\n",
    "To do this, first create two NumPy arrays named `train_indices` and `test_indices`. `train_indices` should contain a *random* 80% of the indices in `full_data`, and `test_indices` should contain the remaining 20% of the indices. Then, use these arrays to index into `full_data` to create your final `train` and `test` DataFrames.\n",
    "\n",
    "*The provided tests check that you not only answered correctly, but ended up with the exact same train/test split as our reference implementation. Later testing is easier this way.*\n",
    "\n",
    "**Note**: You should not be importing any additional libraries for this question. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook. You do not need this line to run train_test_split in general\n",
    "\n",
    "# DO NOT CHANGE THIS LINE\n",
    "np.random.seed(1337)\n",
    "# DO NOT CHANGE THIS LINE\n",
    "\n",
    "def train_test_split(data):\n",
    "    data_len = data.shape[0]\n",
    "    shuffled_indices = np.random.permutation(data_len)\n",
    "    eighty_percent = int(0.8 * data_len)\n",
    "    train_indices = shuffled_indices[0:eighty_percent]\n",
    "    test_indices = shuffled_indices[eighty_percent:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "    \n",
    "train, test = train_test_split(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fit our updated linear regression model using the ordinary least squares estimator! We will start you off with something simple by using only 2 features: the **number of bedrooms** in the household and the **log-transformed total area covered by the building** (in square feet). \n",
    "\n",
    "Consider the following expression for our 1st linear model that contains one of the features:\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms})\n",
    "$$\n",
    "\n",
    "In parallel, we will also consider a 2nd model that contains both features:\n",
    "\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms}) + \\theta_2 \\cdot (\\text{Log Building Square Feet})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 2\n",
    "\n",
    "**Without running any calculation or code**, complete the following statement by filling in the blank with one of the  comparators below:\n",
    "\n",
    "$$\\ge$$\n",
    "$$\\le$$\n",
    "$$=$$\n",
    "\n",
    "Suppose we quantify the loss on our linear models using MSE (Mean Squared Error). Consider the training loss of the 1st model and the training loss of the 2nd model. We are guaranteed that:\n",
    "\n",
    "$$\n",
    "\\text{Training Loss of the 1st Model}  \\_\\_\\_\\_\\_  \\text{Training Loss of the 2nd Model}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\ge$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 3\n",
    "\n",
    "In part A, you wrote a few functions that added features to the dataset. Instead of manually calling each function to add these features to the dataset, it is best practice to encapsulate all of this feature engineering into one \"pipeline\" function. Defining and using a pipeline reduces all the feature engineering to just one function call and ensures that the same transformations are applied to all data. In this question, we will build a pipeline with the function `process_data_gm`. \n",
    "\n",
    "Take a look at the following function `process_data_gm`, which takes in a dataframe `data`, a list `pipeline_functions` containing 3-element tuples `(function, arguments, keyword_arguments)` that will be called on `data` in the pipeline, and the label `prediction_col` that represents the column of our target variable (`Sale Price` in this case). It returns two NumPy arrays: `X`, which is our design matrix, and `y` which is the vector containing the observed data. Take a look at our use of [pd.DataFrame.pipe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html); you can use this function with each of the tuples passed in through `pipeline_functions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_func import *    # imports functions from Project 1A\n",
    "# run this cell to define process_data_gm and select_columns\n",
    "\n",
    "def process_data_gm(data, pipeline_functions, prediction_col):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    for function, arguments, keyword_arguments in pipeline_functions:\n",
    "        if keyword_arguments and (not arguments):\n",
    "            data = data.pipe(function, **keyword_arguments)\n",
    "        elif (not keyword_arguments) and (arguments):\n",
    "            data = data.pipe(function, *arguments)\n",
    "        else:\n",
    "            data = data.pipe(function)\n",
    "    X = data.drop(columns=[prediction_col]).to_numpy()\n",
    "    y = data.loc[:, prediction_col].to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def log_transform(data, col):\n",
    "    \"\"\"Add the log transformation of a column to the data frame\"\"\"\n",
    "    data['Log ' + col] = np.log(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to prepare the training and validation data for the two models we proposed above. Use the following 2 cells to reload a fresh dataset from scratch and run them through the following preprocessing steps for each model:\n",
    "\n",
    "- Perform a `train_test_split` on the original dataset. Let 80% of the set be training data and 20% of the set be validation data. **Even though we are splitting our dataset into training and validation sets, this question will refer to the validation set as the test set.**\n",
    "- For both the training and validation set,\n",
    "    1. Remove outliers in `Sale Price` by so that we are considering households with a price that is strictly greater than 499 dollars (i.e., greater than or equal to 500 dollars). \n",
    "    2. Apply log transformations to `Sale Price` and the `Building Square Feet` columns to create 2 new columns `Log Sale Price` and `Log Building Square Feet`.\n",
    "    3. Extract the total number of bedrooms into a new column `Bedrooms` from the `Description` column.\n",
    "    4. Select the columns `Log Sale Price` and `Bedrooms` (and `Log Building Square Feet` as well if this is the 2nd model).\n",
    "    5. Return the design matrix $X$ and the observed vector $y$. **Your design matrix and observed vector should either be numpy arrays or pandas dataframes**.\n",
    "    \n",
    "\n",
    "Assign the final training data and validation data for both models to the following set of variables:\n",
    "\n",
    "- 1st Model: `X_train_m1`, `y_train_m1`, `X_test_m1`, `y_test_m1`\n",
    "- 2nd Model: `X_train_m2`, `y_train_m2`, `X_test_m2`, `y_test_m2`\n",
    "\n",
    "**We have automatically imported staff implementations of the functions you wrote in Project 1A.** These functions are `remove_outliers`, `add_total_bedrooms`, `find_expensive_neighborhoods`, `add_in_expensive_neighborhood`, and `ohe_roof_material`. You are welcome to copy over your own implementations if you like.\n",
    "\n",
    "**Hint:** We have processed the data for the first model for you below to use as an example.\n",
    "\n",
    "**Note**: Do not change the line `np.random.seed(1337)` as it ensures we are partitioning the dataset exactly the same way for both models (otherwise their performance isn't directly comparable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the data\n",
    "full_data = pd.read_csv(\"cook_county_train.csv\")\n",
    "\n",
    "# Process the data using the pipeline for the first model\n",
    "np.random.seed(1337)\n",
    "train_m1, test_m1 = train_test_split(full_data)\n",
    "\n",
    "m1_pipelines = [\n",
    "    (remove_outliers, None, {\n",
    "        'variable': 'Sale Price',\n",
    "        'lower': 499,\n",
    "    }),\n",
    "    (log_transform, None, {'col': 'Sale Price'}),\n",
    "    (add_total_bedrooms, None, None),\n",
    "    (select_columns, ['Log Sale Price', 'Bedrooms'], None)\n",
    "]\n",
    "\n",
    "\n",
    "X_train_m1, y_train_m1 = process_data_gm(train_m1, m1_pipelines, 'Log Sale Price')\n",
    "X_test_m1, y_test_m1 = process_data_gm(test_m1, m1_pipelines, 'Log Sale Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS LINE\n",
    "np.random.seed(1337)\n",
    "# DO NOT CHANGE THIS LINE\n",
    "\n",
    "\n",
    "# Process the data using the pipeline for the second model\n",
    "m2_pipeline = [\n",
    "    (remove_outliers, None, {\n",
    "        'variable': 'Sale Price',\n",
    "        'lower': 499,\n",
    "    }),\n",
    "    (log_transform, None, {'col': 'Sale Price'}),\n",
    "    (log_transform, None, {'col': 'Building Square Feet'}),\n",
    "    (add_total_bedrooms, None, None),\n",
    "    (select_columns, ['Log Sale Price', 'Bedrooms', 'Log Building Square Feet'], None)\n",
    "]\n",
    "\n",
    "X_train_m2, y_train_m2 = process_data_gm(train_m1, m2_pipeline, 'Log Sale Price')\n",
    "X_test_m2, y_test_m2 = process_data_gm(test_m1, m2_pipeline, 'Log Sale Price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Finally, let's do some regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize a [`sklearn.linear_model.LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object for both of our models. We set the `fit_intercept = True` to ensure that the linear model has a non-zero intercept (i.e., a bias term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_m1 = lm.LinearRegression(fit_intercept=True)\n",
    "linear_model_m2 = lm.LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to fit our linear regression model. Use the cell below to fit both models, and then use it to compute the fitted values of `Log Sale Price` over the training data, and the predicted values of `Log Sale Price` for the testing data.\n",
    "\n",
    "Assign the predicted values from both of your models on the training and testing set to the following variables:\n",
    "\n",
    "- 1st Model: prediction on training set: `y_fitted_m1`, prediction on testing set: `y_predicted_m1`\n",
    "- 2nd Model: prediction on training set: `y_fitted_m2`, prediction on testing set: `y_predicted_m2`\n",
    "\n",
    "**Note**: To make sure you understand how to find the predicted value for both the training and testing data set, there won't be any hidden tests for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the 1st model\n",
    "# Compute the fitted and predicted values of Log Sale Price for 1st model\n",
    "linear_model_m1.fit(X_train_m1, y_train_m1)\n",
    "y_fitted_m1 = linear_model_m1.predict(X_train_m1)\n",
    "y_predicted_m1 = linear_model_m1.predict(X_test_m1)\n",
    "\n",
    "# Fit the 2nd model\n",
    "# Compute the fitted and predicted values of Log Sale Price for 2nd model\n",
    "linear_model_m2.fit(X_train_m2, y_train_m2)\n",
    "y_fitted_m2 = linear_model_m2.predict(X_train_m2)\n",
    "y_predicted_m2 = linear_model_m2.predict(X_test_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "We are moving into analysis of our two models! Let's compare the performance of our two regression models using the Root Mean Squared Error function.\n",
    "\n",
    "$$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in test set}}(\\text{actual price for house} - \\text{predicted price for house})^2}{\\text{number of of houses}}}$$\n",
    "\n",
    "The function is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmse(predicted, actual):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      predicted (1D array): vector of predicted/fitted values\n",
    "      actual (1D array): vector of actual values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fitted_m1, y_train_m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your `rmse` function to calculate the training error and test error for both models in the cell below.\n",
    "\n",
    "Assign the error from both of your models to the following variables:\n",
    "\n",
    "- 1st model: `training_error_m1`, `test_error_m1`\n",
    "- 2nd model: `training_error_m2`, `test_error_m2`\n",
    "\n",
    "Since the target variable we are working with is log-transformed, it can also be beneficial to transform it back to its original form so we will have more context on how our model is performing when compared to actual housing prices.\n",
    "\n",
    "Assign the error on the \"de-log-transformed\" sale price from both of your models to the following variables:\n",
    "\n",
    "- 1st model: `training_error_m1_delog`, `test_error_m1_delog`\n",
    "- 2nd model: `training_error_m2_delog`, `test_error_m2_delog`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and test errors for the 1st model\n",
    "training_error_m1 = rmse(y_fitted_m1, y_train_m1)\n",
    "test_error_m1 = rmse(y_predicted_m1, y_test_m1)\n",
    "\n",
    "# Training and test errors for the 1st model (in its original values before the log transform)\n",
    "\n",
    "\n",
    "training_error_m1_delog = rmse(np.exp(y_fitted_m1), np.exp(y_train_m1))\n",
    "test_error_m1_delog = rmse(np.exp(y_predicted_m1), np.exp(y_test_m1))\n",
    "\n",
    "\n",
    "# Training and test errors for the 2nd model\n",
    "training_error_m2 = rmse(y_fitted_m2, y_train_m2)\n",
    "test_error_m2 = rmse(y_predicted_m2, y_test_m2)\n",
    "\n",
    "\n",
    "# Training and test errors for the 2nd model (in its original values before the log transform)\n",
    "\n",
    "\n",
    "training_error_m2_delog = rmse(np.exp(y_fitted_m2), np.exp(y_train_m2))\n",
    "test_error_m2_delog = rmse(np.exp(y_predicted_m2), np.exp(y_test_m2))\n",
    "\n",
    "print(\"1st Model\\nTraining RMSE: {}\\nTest RMSE: {}\\n\".format(training_error_m1, test_error_m1))\n",
    "print(\"1st Model (no log transform)\\nTraining RMSE: {}\\nTest RMSE: {}\\n\".format(training_error_m1_delog, test_error_m1_delog))\n",
    "print(\"2nd Model\\nTraining RMSE: {}\\nTest RMSE: {}\\n\".format(training_error_m2, test_error_m2))\n",
    "print(\"2nd Model (no log transform)\\nTraining RMSE: {}\\nTest RMSE: {}\\n\".format(training_error_m2_delog, test_error_m2_delog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 6\n",
    "\n",
    "Let's compare the actual parameters ($\\theta_0$ and $\\theta_1$) from both of our models. As a quick reminder,\n",
    "\n",
    "for the 1st model,\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms})\n",
    "$$\n",
    "\n",
    "for the 2nd model,\n",
    "$$\n",
    "\\text{Log Sale Price} = \\theta_0 + \\theta_1 \\cdot (\\text{Bedrooms}) + \\theta_2 \\cdot (\\text{Log Building Square Feet})\n",
    "$$\n",
    "\n",
    "Run the following cell and compare the values of $\\theta_1$ from both models. Why does $\\theta_1$ change from positive to negative when we introduce an additional feature in our 2nd model? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we add another feature in our model normally the variance decreases, however, the error of the model incrases. So, in this example $\\theta_1$ changes to negative because error incrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters from 1st model\n",
    "theta0_m1 = linear_model_m1.intercept_\n",
    "theta1_m1 = linear_model_m1.coef_[0]\n",
    "\n",
    "# Parameters from 2nd model\n",
    "theta0_m2 = linear_model_m2.intercept_\n",
    "theta1_m2, theta2_m2 = linear_model_m2.coef_\n",
    "\n",
    "print(\"1st Model\\nθ0: {}\\nθ1: {}\".format(theta0_m1, theta1_m1))\n",
    "print(\"2nd Model\\nθ0: {}\\nθ1: {}\\nθ2: {}\".format(theta0_m2, theta1_m2, theta2_m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 7\n",
    "### Question 7a\n",
    "\n",
    "Another way of understanding the performance (and appropriateness) of a model is through a plot of the model the residuals versus the observations.\n",
    "\n",
    "In the cell below, use [`plt.scatter`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html) to plot the residuals from predicting `Log Sale Price` using **only the 2nd model** against the original `Log Sale Price` for the **test data**. You should also ensure that the dot size and opacity in the scatter plot are set appropriately to reduce the impact of overplotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d79f42d60b94fca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "plt.scatter(x=y_predicted_m2, y=y_test_m2, s=3, alpha=0.75)\n",
    "plt.xlabel('Predicted Log Sale Price - Y_hat')\n",
    "plt.ylabel('Original Log Sale Price - Y')\n",
    "plt.title('Log Sale Price vs Sale Price Using Model_2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 7b\n",
    "\n",
    "Based on the structure you see in your plot, does this model seem like it will correspond to _regressive_, _fair_, or _progressive_ taxation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q7b = 'regressive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our simple model explains some of the variability in price, there is certainly still a lot of room for improvement to be made -- one reason is we have been only utilizing 1 or 2 features (out of a total of 70+) so far! Can you engineer and incoporate more features to improve the model's fairness and accuracy? We won't be asking you to provide your answers here, but this would be important going into the next part (also last part, wohoo!) of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "It is time to build your own model!\n",
    "\n",
    "Just as in the guided model from the previous question, you should encapsulate as much of your workflow into functions as possible. Your job is to select better features and define your own feature engineering pipeline inside the function `process_data_fm` in the following cell. **You must not change the parameters inside `process_data_fm`**.\n",
    "\n",
    "To evaluate your model, we will start by defining a linear regression model. Then, we will process training data using your `process_data_fm`, fit the model with this training data, and compute the training RMSE. Then, we will process some test data with your `process_data_fm`, use the model to predict `Log Sale Price` for the test data, transform the predicted and original log values back into their original forms (by using `delog`), and compute the test RMSE.\n",
    "\n",
    "**Notes**: \n",
    "- **If you are running into memory issues, restart kernel and only run the cells you need to.** The cell below (question cell) contains most to all of the imports necessary to successfully complete this portion of the project, so it can be completed (almost) independently code-wise from the remainder of the project. The autograder will have more than 2 GB memory, so you will not lose credit as long as your solution to Question 8 is within the total memory limits of DataHub. Alternatively, you can delete variables you are not using through `del` or `%reset -f`. For example, this will free up memory from data used for older models: `del training_data, test_data, train, test, X_train_m1, X_test_m1, X_train_m2, X_test_m1`. Our staff solution (Summer 2022) can be run independently from all other questions, so we encourage you to do the same to make debugging easier.\n",
    "- `delog` is a function we will run to undo the log transformation on your predictions/original sale prices. Before submitting to Gradescope, make sure that your predicted values can all be delogged (i.e. if the value is 100, it is too large - $e^{100}$ is too big!)\n",
    "- We will **not** use the test data as provided in `cook_county_test.csv`, but we will assess your model using `cook_county_contest_test.csv`. \n",
    "- You **MUST remove any additional new cells you add below the current one before submitting to Gradescope** to avoid any autograder errors. \n",
    "- Do **not** edit the two lines at the end of the question cell below - if you do, you will receive no credit for this question.\n",
    "- You cound only submit the csv file to gradescope up to **3 times** per day. \n",
    "\n",
    "\n",
    "**Hints:** \n",
    "- Some features may have missing values in the test set but not in the training set. Make sure `process_data_fm` handles missing values appropriately for each feature!\n",
    "- Pay a *lot* of attention to how you filter your outliers. Treat your upper outlier percentile as a hyperparameter. How can we filter the optimal number of outliers to obtain the best possible test RMSE?\n",
    "- Using the pipline as we have seen in Question 3 might not work if you are doing one-hot encoding. Consider writing general function to process training and test set.\n",
    "\n",
    "\n",
    "### Grading Scheme\n",
    "\n",
    "Your grade for Question 8 will be based on your training RMSE and contest **test** RMSE (note that this is another test set, separate from our existing test set!). The thresholds are as follows:\n",
    "\n",
    "Points | 3 | 2 | 1 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "Training RMSE | Less than 200k | [200k, 240k) | [240k, 280k) | More than 280k\n",
    "\n",
    "Points | 3 | 2 | 1 | 0\n",
    "--- | --- | --- | --- | ---\n",
    "Test RMSE | Less than 240k | [240k, 280k) | [280k, 300k) | More than 300k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define any additional helper functions you need here\n",
    "\n",
    "# Uncomment the line below to clean up memory from previous questions and reinitialize Otter!\n",
    "# MAKE SURE TO COMMENT THE NEXT 3 LINES OUT BEFORE SUBMITTING!\n",
    "#%reset -f\n",
    "#import otter\n",
    "#grader = otter.Notebook(\"proj1b.ipynb\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "from ds100_utils import *\n",
    "from feature_func import *\n",
    "\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def log_transform(data, col):\n",
    "    \"\"\"Add the log transformation of a column to the data frame\"\"\"\n",
    "    data['Log ' + col] = np.log(data[col])\n",
    "    return data\n",
    "\n",
    "def log2_transform(data, col):\n",
    "    \"\"\"Add the log transformation of a column to the data frame\"\"\"\n",
    "    data['Log ' + col] = np.log(data[col]+1)\n",
    "    return data\n",
    "\n",
    "def square_transform(data, col):\n",
    "    data['Sqr ' + col] = data[col]**2\n",
    "    return data\n",
    "def cube_transform(data, col):\n",
    "    data['Cube ' + col] = data[col]**3 \n",
    "    return data\n",
    "def root_transform(data, col):\n",
    "    data['Root ' + col] = np.sqrt(data[col])\n",
    "    return data\n",
    "\n",
    "def add_total_rooms(data): \n",
    "    \"\"\"\n",
    "    Input:\n",
    "    data (data frame): a data frame containing at least the Description column.\n",
    "    \"\"\"\n",
    "    with_rooms = data.copy()\n",
    "    rooms_regex = r'has a total of (\\d+) rooms'\n",
    "    rooms = with_rooms['Description'].str.extract(rooms_regex).astype(int) \n",
    "    with_rooms['Rooms'] = rooms\n",
    "    return with_rooms\n",
    "\n",
    "\n",
    "\n",
    "# Please include all of your feature engineering process inside this function.\n",
    "# Do not modify the parameters of this function.\n",
    "def process_data_fm(data, is_test_set=False):\n",
    "    # Whenever you access 'Log Sale Price' or 'Sale Price', make sure to use the\n",
    "    # condition is_test_set like this:\n",
    "    \n",
    "    if not is_test_set:\n",
    "        # do your processing for the training set (i.e. not the test set)\n",
    "        # this can involve references to sale price!\n",
    "        # data['Log Sale Price'] = np.log(data['Sale Price'])\n",
    "        data = ohe_roof_material(data)\n",
    "        pipeline = [\n",
    "            (remove_outliers, None, {\n",
    "                'variable': 'Sale Price',\n",
    "                'lower': np.percentile(data['Sale Price'], 5),\n",
    "                'upper': np.percentile(data['Sale Price'], 95)}),\n",
    "            (log_transform, None, {'col': 'Sale Price'}),\n",
    "            (log_transform, None, {'col': 'Building Square Feet'}),\n",
    "            (root_transform, None, {'col': 'Garage 1 Area'}),\n",
    "            (root_transform, None, {'col': 'Garage 2 Area'}),\n",
    "            (log2_transform, None, {'col': 'Estimate (Land)'}),\n",
    "            (log2_transform, None, {'col': 'Estimate (Building)'}),\n",
    "            (cube_transform, None, {'col': 'Age'}),\n",
    "            (log_transform, None, {'col': 'Sale Month of Year'}),\n",
    "            (square_transform, None, {'col': 'Lot Size'}),\n",
    "            (add_total_bedrooms, None, None),\n",
    "            (add_total_rooms, None, None),\n",
    "            (square_transform, None, {'col': 'Rooms'}),\n",
    "            (square_transform, None, {'col': 'Bedrooms'}),\n",
    "            (square_transform, None, {'col': 'Property Class'}),\n",
    "            (square_transform, None, {'col': 'Land Square Feet'}),\n",
    "            (cube_transform, None, {'col': 'Rooms'}),\n",
    "            \n",
    "            \n",
    "            (select_columns, ['Log Sale Price',\n",
    "                              'Log Building Square Feet',\n",
    "                              'Log Estimate (Land)', \n",
    "                              'Log Estimate (Building)',\n",
    "                              'PIN',\n",
    "                              'Attic Finish',\n",
    "                              'Property Class',\n",
    "                              'Sqr Property Class',\n",
    "                              'Neighborhood Code',\n",
    "                              'Land Square Feet',\n",
    "                              'Sqr Land Square Feet',\n",
    "                              'Basement',\n",
    "                              'Cathedral Ceiling',\n",
    "                              'Garage 1 Attachment',\n",
    "                              'Garage 2 Attachment',\n",
    "                              'Building Square Feet',\n",
    "                              'Multi Code',\n",
    "                              'Floodplain',\n",
    "                              'Census Tract',\n",
    "                              'Construction Quality', \n",
    "                              'Sqr Lot Size', \n",
    "                              'Basement Finish',\n",
    "                              'Sqr Rooms',\n",
    "                              'Roof Material_2.0',\n",
    "                              'Roof Material_5.0',\n",
    "                              'Roof Material_6.0',\n",
    "                              'Cube Rooms',\n",
    "                              'Bedrooms'], None)\n",
    "        ]\n",
    "        \n",
    "    \n",
    "        for function, arguments, keyword_arguments in pipeline: \n",
    "            if keyword_arguments and (not arguments):\n",
    "                data = data.pipe(function, **keyword_arguments)\n",
    "            \n",
    "            elif (not keyword_arguments) and (arguments):\n",
    "                data = data.pipe(function, *arguments)\n",
    "                \n",
    "            else: \n",
    "                data = data.pipe(function) \n",
    "    else:\n",
    "        #...\n",
    "        # do your processing for the test set\n",
    "        # this CANNOT involve references to sale price!\n",
    "        data = ohe_roof_material(data)\n",
    "        pipeline = [\n",
    "            (log_transform, None, {'col': 'Building Square Feet'}),\n",
    "            (root_transform, None, {'col': 'Garage 1 Area'}),\n",
    "            (root_transform, None, {'col': 'Garage 2 Area'}),\n",
    "            (log2_transform, None, {'col': 'Estimate (Land)'}),\n",
    "            (log2_transform, None, {'col': 'Estimate (Building)'}),\n",
    "            (cube_transform, None, {'col': 'Age'}),\n",
    "            (log_transform, None, {'col': 'Sale Month of Year'}),\n",
    "            (square_transform, None, {'col': 'Lot Size'}),\n",
    "            (add_total_bedrooms, None, None),\n",
    "            (add_total_rooms, None, None),\n",
    "            (square_transform, None, {'col': 'Rooms'}),\n",
    "            (square_transform, None, {'col': 'Bedrooms'}),\n",
    "            (square_transform, None, {'col': 'Property Class'}),\n",
    "            (square_transform, None, {'col': 'Land Square Feet'}),\n",
    "            (cube_transform, None, {'col': 'Rooms'}),\n",
    "            \n",
    "            (select_columns, ['Log Building Square Feet',\n",
    "                              'Log Estimate (Land)', \n",
    "                              'Log Estimate (Building)',\n",
    "                              'PIN',\n",
    "                              'Attic Finish',\n",
    "                              'Property Class',\n",
    "                              'Sqr Property Class',\n",
    "                              'Neighborhood Code',\n",
    "                              'Land Square Feet',\n",
    "                              'Sqr Land Square Feet',\n",
    "                              'Basement',\n",
    "                              'Cathedral Ceiling',\n",
    "                              'Garage 1 Attachment',\n",
    "                              'Garage 2 Attachment',\n",
    "                              'Building Square Feet',\n",
    "                              'Multi Code',\n",
    "                              'Floodplain',\n",
    "                              'Census Tract',\n",
    "                              'Construction Quality', \n",
    "                              'Sqr Lot Size', \n",
    "                              'Basement Finish',\n",
    "                              'Sqr Rooms',\n",
    "                              'Roof Material_2.0',\n",
    "                              'Roof Material_5.0',\n",
    "                              'Roof Material_6.0',\n",
    "                              'Cube Rooms',\n",
    "                              'Bedrooms'], None)\n",
    "        ]\n",
    "    \n",
    "        for function, arguments, keyword_arguments in pipeline: \n",
    "            if keyword_arguments and (not arguments):\n",
    "                data = data.pipe(function, **keyword_arguments)\n",
    "            \n",
    "            elif (not keyword_arguments) and (arguments):\n",
    "                data = data.pipe(function, *arguments)\n",
    "                \n",
    "            else: \n",
    "                data = data.pipe(function) \n",
    "    #data = ohe_roof_material(data)\n",
    "    # Return predictors (x) and response variables separately (y)\n",
    "    if is_test_set:\n",
    "        X = data\n",
    "        #... # any other processing you wish to do\n",
    "        return X\n",
    "    else:\n",
    "        X = data.drop(['Log Sale Price'], axis = 1)\n",
    "        y = data.loc[:, 'Log Sale Price']\n",
    "        #... # any other processing you wish to do\n",
    "        return X, y\n",
    "\n",
    "# DO NOT EDIT THESE TWO LINES!\n",
    "check_rmse_threshold = run_linear_regression_test_optim(lm.LinearRegression(fit_intercept=True), process_data_fm, 'cook_county_train.csv', None, False)\n",
    "print(\"Current training RMSE:\", check_rmse_threshold.loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the error on the test set, please submit your predictions on the contest test set to the Gradescope assignment: **Project 1B Test Set Predictions**. The CSV file to submit is generated below and you should not modify the cell below. Simply download the CSV file and submit it to the appropriate Gradescope assignment.\n",
    "\n",
    "Note that **you will not receive credit for the test set predictions (i.e. up to 3 points) unless you submit to this assignment**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "Y_test_pred = run_linear_regression_test(lm.LinearRegression(fit_intercept=True), process_data_fm, None, 'cook_county_train.csv', 'cook_county_contest_test.csv', \n",
    "                                         is_test = True, is_ranking = False, return_predictions = True\n",
    "                                         )\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": pd.read_csv('cook_county_contest_test.csv')['Unnamed: 0'], \n",
    "    \"Value\": Y_test_pred,\n",
    "}, columns=['Id', 'Value'])\n",
    "timestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\n",
    "submission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n",
    "\n",
    "print('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\n",
    "print('You may now upload this CSV file to Gradescope for scoring.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 9\n",
    "\n",
    "In building your model in question 8, what different models have you tried? What worked and what did not? Brief discuss your modeling process.\n",
    "\n",
    "Note: We are looking for a single correct answer. Explain what you did in question 8 and you will get point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I used some features without transforming them which made the error larger. Then I transformed them based on their bulges direction. I have noticed the error getting smaller and smaller. However, I needed to do one hot encoding to make the error more smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Congratulations on finishing your prediction model for home sale prices in Cook County! In the following section, we'll delve deeper into the implications of predictive modeling within the CCAO case study - especially because statistical modeling is how the CCAO valuates properties. \n",
    "\n",
    "Refer to [Lecture 14](https://ds100.org/fa22/lecture/lec14/) if you're having trouble getting started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 10\n",
    "\n",
    "When evaluating your model, we used root mean squared error. In the context of estimating the value of houses, what does error mean for an individual homeowner? How does it affect them in terms of property taxes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an individual homeowner the error means a difference betweeen the actual value of the house and the predicted value. Therefore, the homeowner would have to pay either less or high property taxes. On the other hand, the error is a bias against homeowners in Cook County. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "In the case of the Cook County Assessor’s Office, Chief Data Officer Rob Ross states that fair property tax rates are contingent on whether property values are assessed accurately - that they’re valued at what they’re worth, relative to properties with similar characteristics. This implies that having a more accurate model results in fairer assessments. The goal of the property assessment process for the CCAO, then, is to be as accurate as possible. \n",
    "\n",
    "When the use of algorithms and statistical modeling has real-world consequences, we often refer to the idea of fairness as a measurement of how socially responsible our work is. But fairness is incredibly multifaceted: Is a fair model one that minimizes loss - one that generates accurate results? Is it one that utilizes \"unbiased\" data? Or is fairness a broader goal that takes historical contexts into account?\n",
    "\n",
    "These approaches to fairness are not mutually exclusive. If we look beyond error functions and technical measures of accuracy, we'd not only consider _individual_ cases of fairness, but also what fairness - and justice - means to marginalized communities on a broader scale. We'd ask: What does it mean when homes in predominantly Black and Hispanic communities in Cook County are consistently overvalued, resulting in proportionally higher property taxes? When the white neighborhoods in Cook County are consistently undervalued, resulting in proportionally lower property taxes? \n",
    "\n",
    "Having \"accurate\" predictions doesn't necessarily address larger historical trends and inequities, and fairness in property assessments in taxes works beyond the CCAO's valuation model. Disassociating accurate predictions from a fair system is vital to approaching justice at multiple levels. Take Evanston, IL - a suburb in Cook County - as an example of housing equity beyond just improving a property valuation model: Their City Council members [recently approved reparations for African American residents](https://www.usnews.com/news/health-news/articles/2021-03-23/chicago-suburb-approves-government-reparations-for-black-residents).\n",
    "\n",
    "\n",
    "## Question 11\n",
    "\n",
    "In your own words, describe how you would define fairness in property assessments and taxes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my openion, fairness in property assements and taxes means building good models to predict housing values as accurate as possible. This means property evaluation should be dependent of factors related to the property without considering their owner. It seems in Cook County they didn't practice fairness as well as they didn't consider equality which affected their model and ultimatley the people of color, lower income, and minorities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## The CCAO and Transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, in their approach to fair property valuations, the CCAO has also pushed for transparency initiatives in the property tax assessment system. After a lawsuit was filed against the CCAO for producing [“racially discriminatory assessments and taxes,\"](https://harris.uchicago.edu/news-events/news/prof-chris-berry-testifies-institutional-racism-cook-county-property-taxes) the Office decided that these inequities would be best addressed by making the assessment process more transparent to Cook County constituents.  \n",
    "\n",
    "These transparency initiatives include publishing all of the CCAO’s work on [GitLab](https://gitlab.com/ccao-data-science---modeling). By allowing the public to access any updates to the system in real-time, the Office argues that they increase accessibility to a process that had previously been blackboxed - obscured and hidden - from the public. Ultimately, the hope is that, by exposing the inner workings of the CCAO’s property valuation process, the CCAO's assessment results could be publicly verified as accurate and therefore trusted to be fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 12\n",
    "\n",
    "Take a look at the Residential Automated Valuation Model files under the Models subgroup in the CCAO’s [GitLab](https://gitlab.com/ccao-data-science---modeling). Without directly looking at any code, do you feel that the documentation sufficiently explains how the residential valuation model works? Which part(s) of the documentation might be difficult for nontechnical audiences to understand?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation looks ok in terms of how the residential model workds. However, I realized the flow chart is complex and difficult to understand even for technical audiences. Also, I would have suggest to include some explanation to some technical terms (e.g., regularization, over-fitting etc.) in the Model Selection so that it would have become easier for ordinary people/non-technical audiences to understand the terms and ultimatley the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "You might feel that the model's inner workings are beyond your pay grade - it's far more complex than the model you built in this assignment, after all! Though we won't delve further into the role of transparency in the broader CCAO case study, consider its effectiveness and/or ineffectiveness: Is the system truly transparent if it's inaccessible to Cook County constituents? Do transparency measures actually bolster the accuracy of a model - or do they only affect the _perceived_ accuracy of a model? \n",
    "\n",
    "And if you're interested in thinking more about transparency measures, take Data 104! But for now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have finished Project 1B!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q0c": {
     "name": "q0c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q0c.lower() in ['a', 'b', 'c']\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1": {
     "name": "q1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> train.shape == (163833, 62) # train should contain 80% of the data\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test.shape == (40959, 62) # test should contain 20% of the data\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(train[\"Sale Price\"].mean(), 244939.22668204817, atol=0.1) # If this doesn't match, you might have still answered the question, but please adjust your code so that your split matches ours by following the implementation instructions about using shuffled_indices to split the data.\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(test[\"Sale Price\"].mean(), 246066.1821089382, atol=0.1) # If this doesn't match, you might have still answered the question, but please adjust your code so that your split matches ours by following the implementation instructions about using shuffled_indices to split the data.\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (type(X_train_m1) in (np.ndarray, pd.core.frame.DataFrame)) and \\\n... (type(y_train_m1) in (np.ndarray, pd.core.frame.DataFrame)) and \\\n... (type(X_test_m1) in (np.ndarray, pd.core.frame.DataFrame)) and \\\n... (type(y_test_m1) in (np.ndarray, pd.core.frame.DataFrame)) and \\\n... (type(X_train_m2) in (np.ndarray, pd.core.frame.DataFrame)) and \\\n... (type(y_train_m2) in (np.ndarray, pd.core.frame.DataFrame)) and \\\n... (type(X_test_m2) in (np.ndarray, pd.core.frame.DataFrame)) and \\\n... (type(y_test_m2) in (np.ndarray, pd.core.frame.DataFrame))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(y_fitted_m1.max(), 17.528601849438104, atol=0.0001) == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(y_fitted_m2.max(), 15.614096224439168, atol=0.0001) == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(y_predicted_m1.max(), 15.540922864181525, atol=0.0001) == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(y_predicted_m2.max(), 15.02563963305767, atol=0.0001) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (training_error_m1 > 0) and (test_error_m1 > 0) == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> (training_error_m2 > 0) and (test_error_m2 > 0) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7b": {
     "name": "q7b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q7b.lower() in [\"regressive\", \"fair\", \"progressive\"]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> check_rmse_threshold(200000)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> check_rmse_threshold(240000)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> check_rmse_threshold(280000)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
